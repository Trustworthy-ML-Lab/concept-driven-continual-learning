{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "976d36de-ab56-4f3b-a81a-200aaf76b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#virtually move to parent directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "import clip\n",
    "import utils\n",
    "import similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1724590a-2333-4daa-9948-6be1dfc60c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arguments\n",
    "clip_name = 'ViT-B/16'\n",
    "target_name = 'resnet50'\n",
    "target_layer = 'fc'\n",
    "d_probe = 'imagenet_broden'#\"cifar100_train\"#\"imagenet_val\"#\"broden\"#\"imagenet_broden\"\n",
    "\n",
    "batch_size = 200\n",
    "device = 'cuda'\n",
    "pool_mode = 'avg'\n",
    "\n",
    "save_dir = 'saved_activations'\n",
    "target_preprocess = utils.get_resnet_imagenet_preprocess()\n",
    "similarity_fn = similarity.soft_wpmi #wpmi, rank_reorder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfa97eb-1e6a-45c5-96e5-3d5724be0c13",
   "metadata": {},
   "source": [
    "# Cos similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6a1e91-5363-43a3-8f0b-4a034515923e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 843.98it/s]\n"
     ]
    }
   ],
   "source": [
    "concept_set = 'data/20k.txt'\n",
    "\n",
    "utils.save_activations(clip_name = clip_name, target_name = target_name, target_layers = [target_layer], \n",
    "                       d_probe = d_probe, concept_set = concept_set, batch_size = batch_size, \n",
    "                       device = device, pool_mode=pool_mode, target_preprocess = target_preprocess,\n",
    "                      save_dir = save_dir)\n",
    "\n",
    "save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                                  target_layer = target_layer, d_probe = d_probe,\n",
    "                                  concept_set = concept_set, pool_mode=pool_mode,\n",
    "                                  save_dir = save_dir)\n",
    "\n",
    "target_save_name, clip_save_name, text_save_name = save_names\n",
    "\n",
    "similarities, target_feats = utils.get_similarity_from_activations(target_save_name, clip_save_name, \n",
    "                                                        text_save_name, similarity_fn)\n",
    "\n",
    "with open(concept_set, 'r') as f:\n",
    "    words = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ba548c-59fc-4112-8e93-9bb034c0adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "clip_model, _ = clip.load(clip_name, device=device)\n",
    "\n",
    "with open(\"data/imagenet_labels.txt\", \"r\") as f:\n",
    "    cls_id_to_name = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a33a7c1-0acc-444b-a530-baedc39ffe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP-Dissect - Clip similarity: 0.7900, mpnet similarity: 0.5233\n"
     ]
    }
   ],
   "source": [
    "clip_preds = torch.argmax(similarities, dim=1)\n",
    "clip_preds = [words[int(pred)] for pred in clip_preds]\n",
    "\n",
    "clip_cos, mpnet_cos = utils.get_cos_similarity(clip_preds, cls_id_to_name, clip_model, model, device, batch_size)\n",
    "print(\"CLIP-Dissect - Clip similarity: {:.4f}, mpnet similarity: {:.4f}\".format(clip_cos, mpnet_cos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c91edd-85ec-4b37-b7d6-2df042c1f622",
   "metadata": {},
   "source": [
    "# Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae886f7-6e33-4226-8d5e-9e6ccd1699ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4374.03it/s]\n"
     ]
    }
   ],
   "source": [
    "concept_set = 'data/imagenet_labels.txt'\n",
    "\n",
    "utils.save_activations(clip_name = clip_name, target_name = target_name, target_layers = [target_layer], \n",
    "                       d_probe = d_probe, concept_set = concept_set, batch_size = batch_size, \n",
    "                       device = device, pool_mode=pool_mode, target_preprocess = target_preprocess,\n",
    "                      save_dir = save_dir)\n",
    "\n",
    "save_names = utils.get_save_names(clip_name = clip_name, target_name = target_name,\n",
    "                                  target_layer = target_layer, d_probe = d_probe,\n",
    "                                  concept_set = concept_set, pool_mode=pool_mode,\n",
    "                                  save_dir = save_dir)\n",
    "\n",
    "target_save_name, clip_save_name, text_save_name = save_names\n",
    "\n",
    "similarities, target_feats = utils.get_similarity_from_activations(target_save_name, clip_save_name, \n",
    "                                                        text_save_name, similarity_fn)\n",
    "\n",
    "with open(concept_set, 'r') as f: \n",
    "    words = (f.read()).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a71c2a95-1536-4fbc-8bc8-95798fd59d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def get_topk_acc(sim, k=5):\n",
    "    correct = 0\n",
    "    for orig_id in range(1000):\n",
    "        vals, ids = torch.topk(sim[orig_id], k=k)\n",
    "        for idx in ids[:k]:\n",
    "            correct += (int(idx)==orig_id)\n",
    "    return (correct/1000)*100\n",
    "\n",
    "def get_correct_rank_mean_median(sim):\n",
    "    ranks = []\n",
    "    for orig_id in range(1000):\n",
    "        vals, ids = torch.sort(sim[orig_id], descending=True)\n",
    "        \n",
    "        ranks.append(list(ids).index(orig_id)+1)\n",
    "        \n",
    "    mean = sum(ranks)/len(ranks)\n",
    "    median = sorted(ranks)[500]\n",
    "    return mean, median\n",
    "\n",
    "def get_auc(sim):\n",
    "    max_sim, preds = torch.max(sim.cpu(), dim=1)\n",
    "    gtruth = torch.arange(0, 1000)\n",
    "    correct = (preds==gtruth)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(correct, max_sim)\n",
    "    auc = metrics.roc_auc_score(correct, max_sim)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f60b4f49-6829-4da6-9add-94ff0e96a98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP-Dissect Top 1 acc:95.4000\n",
      "CLIP-Dissect Top 5 acc:99.0000\n",
      "Mean rank of correct class:1.194, Median rank of correct class:1\n",
      "AUC:0.9166\n"
     ]
    }
   ],
   "source": [
    "print(\"CLIP-Dissect Top 1 acc:{:.4f}\".format(get_topk_acc(similarities, k=1)))\n",
    "print(\"CLIP-Dissect Top 5 acc:{:.4f}\".format(get_topk_acc(similarities, k=5)))\n",
    "\n",
    "mean, median = get_correct_rank_mean_median(similarities)\n",
    "print(\"Mean rank of correct class:{}, Median rank of correct class:{}\".format(mean, median))\n",
    "print(\"AUC:{:.4f}\".format(get_auc(similarities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a25b23-8cbc-4c34-8369-225a51172802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jovyan-clip]",
   "language": "python",
   "name": "conda-env-jovyan-clip-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
