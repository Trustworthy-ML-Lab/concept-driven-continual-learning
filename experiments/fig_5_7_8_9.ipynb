{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5720aa2-4365-4bd3-b2e8-c52217de46ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import random\n",
    "import utils\n",
    "import data_utils\n",
    "import json\n",
    "\n",
    "import cbm\n",
    "import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b50f004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data='cifar100'\n",
    "task='0'\n",
    "seed='fix'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b486050c-7a36-4339-b9ff-e6b8426dbbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to the correct model dir, everything else should be taken care of\n",
    "model_dir = \"~/concept-driven-continual-learning/results/cbm/SEED_%s/resnet18_%s_5task_20epoch/naive/%s_task_%s_%s_cbm\"%(seed,data,data,task,seed)\n",
    "data_name='%s_task_%s_%s' %(data,task,seed)\n",
    "device = \"cuda\"\n",
    "with open(os.path.join(model_dir, \"args.txt\"), \"r\") as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "#_, target_preprocess = data_utils.get_target_model(args[\"backbone\"],None,None,'False', device)\n",
    "naive_model = cbm.load_cbm(model_dir,None,None,'False','False', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d230356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to the correct model dir, everything else should be taken care of\n",
    "f_model_dir = \"~/concept-driven-continual-learning/results/cbm/SEED_%s/resnet18_%s_5task_20epoch/freeze_reg/%s_task_%s_%s_cbm\"%(seed,data,data,task,seed)\n",
    "data_name='%s_task_%s_%s' %(data,task,seed)\n",
    "device = \"cuda\"\n",
    "with open(os.path.join(f_model_dir, \"args.txt\"), \"r\") as f:\n",
    "    args = json.load(f)\n",
    "\n",
    "#_, target_preprocess = data_utils.get_target_model(args[\"backbone\"],None,None,'False', device)\n",
    "f_model = cbm.load_cbm(f_model_dir,None,None,'False','False', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "309e2bb6-d79d-4de3-bdf4-6b9c3b466682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_, val_data_t = data_utils.get_data(data_name,seed, clip_preprocess=None, target_preprocess=None)\n",
    "#val_pil_data,target = data_utils.get_pil_data(data_name,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5871a0d2-8b18-4bac-aa26-bf3dce49fcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_file = 'data/cifar100_classes.txt'#data_utils.LABEL_FILES[dataset]\n",
    "with open(cls_file, \"r\") as f:\n",
    "    classes = f.read().split(\"\\n\")\n",
    "\n",
    "with open(os.path.join(model_dir, \"concepts.txt\"), \"r\") as f:\n",
    "    concepts = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74501e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(f_model_dir, \"concepts.txt\"), \"r\") as f:\n",
    "    f_concepts = f.read().split(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adb41545",
   "metadata": {},
   "source": [
    "## Show final layer weights for some classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7201ed8e-bbef-4b5a-ab55-4bed2bbb235e",
   "metadata": {},
   "source": [
    "You can build a Sankey diagram of weights by copying the incoming weights printed below into https://sankeymatic.com/build/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f95bd7-a06c-49d0-a7d4-3a190a6083da",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = random.choices([i for i in range(len(classes))], k=1)\n",
    "to_show=[9]\n",
    "for i in to_show:\n",
    "    print(\"Output class:{} - {}\".format(i, classes[i]))\n",
    "    print(\"Incoming weights:\")\n",
    "    for j in range(len(concepts)):\n",
    "        if torch.abs(naive_model.final.weight[i,j])>0.05:\n",
    "            if naive_model.final.weight[i,j]>0:\n",
    "                print(\"{} [{:.4f}] {}\".format(concepts[j], naive_model.final.weight[i,j], classes[i]))\n",
    "            #else:\n",
    "            #    print(\"not {} [{:.4f}] {}\".format(concepts[j], -naive_model.final.weight[i,j], classes[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfce795",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_show = random.choices([i for i in range(len(classes))], k=1)\n",
    "to_show=[18]\n",
    "for i in to_show:\n",
    "    print(\"Output class:{} - {}\".format(i, classes[i]))\n",
    "    print(\"Incoming weights:\")\n",
    "    for j in range(len(f_concepts)):\n",
    "        if torch.abs(f_model.final.weight[i,j])>0.05:\n",
    "            if f_model.final.weight[i,j]>0:\n",
    "                print(\"{} [{:.4f}] {}\".format(f_concepts[j], f_model.final.weight[i,j], classes[i]))\n",
    "            else:\n",
    "                print(\"not {} [{:.4f}] {}\".format(f_concepts[j], -f_model.final.weight[i,j], classes[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
